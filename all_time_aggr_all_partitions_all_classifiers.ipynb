{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pybrain.tools.shortcuts import buildNetwork\n",
    "from pybrain.supervised.trainers import BackpropTrainer\n",
    "from pybrain.utilities           import percentError\n",
    "from pybrain.datasets import SupervisedDataSet\n",
    "from pybrain.datasets            import ClassificationDataSet\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,BaggingClassifier,GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import tree\n",
    "import getfeat\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def part(Y,partition):\n",
    "    \n",
    "    Y_q=np.zeros(len(Y))\n",
    "    i=0\n",
    "    for y in Y:\n",
    "        k=0\n",
    "        score=-1\n",
    "        for p in partition:\n",
    "            if y in p:\n",
    "                score=k\n",
    "                break\n",
    "            k+=1\n",
    "        if score==-1:\n",
    "            score=len(partition)\n",
    "        Y_q[i]=score\n",
    "        i+=1\n",
    "    return Y_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "partitions1=[[[0],[1],[2,3],[4,5]],\n",
    "             [[0],[1,2],[3,4]],\n",
    "             [[0,1],[2,3]]\n",
    "            ]\n",
    "Partitions=[partitions1]\n",
    "for j in [2,3,4,5,6]:\n",
    "    Q=getfeat.get_composed_feat_h(j)\n",
    "    Y=Q[1]\n",
    "    H=np.histogram(Y,list(range(int(max(Y))+1)))\n",
    "    partitions=[]\n",
    "\n",
    "    for D in [5,4,3]:\n",
    "        start=0\n",
    "        partition=[]\n",
    "        for c in range(D-1):\n",
    "            s=0\n",
    "            for i in range(start,len(H[0])):\n",
    "                s+=H[0][i]\n",
    "                if s>len(Y)/float(D):\n",
    "                    break\n",
    "            partition.append(list(range(start,i+1)))\n",
    "            start=i+1\n",
    "        partitions.append(partition)\n",
    "    Partitions.append(partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0], [1], [2, 3], [4, 5]]\n",
      "----\n",
      "[[0], [1, 2], [3, 4]]\n",
      "----\n",
      "[[0, 1], [2, 3]]\n",
      "----\n",
      "****\n",
      "[[0, 1], [2, 3], [4, 5, 6], [7, 8, 9, 10]]\n",
      "----\n",
      "[[0, 1, 2], [3, 4, 5], [6, 7, 8, 9, 10]]\n",
      "----\n",
      "[[0, 1, 2], [3, 4, 5, 6]]\n",
      "----\n",
      "****\n",
      "[[0, 1, 2], [3, 4, 5], [6, 7, 8, 9], [10, 11, 12, 13, 14]]\n",
      "----\n",
      "[[0, 1, 2, 3], [4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14]]\n",
      "----\n",
      "[[0, 1, 2, 3], [4, 5, 6, 7, 8, 9]]\n",
      "----\n",
      "****\n",
      "[[0, 1, 2, 3], [4, 5, 6], [7, 8, 9, 10, 11], [12, 13, 14, 15, 16, 17]]\n",
      "----\n",
      "[[0, 1, 2, 3, 4], [5, 6, 7, 8, 9], [10, 11, 12, 13, 14, 15, 16, 17]]\n",
      "----\n",
      "[[0, 1, 2, 3, 4, 5], [6, 7, 8, 9, 10, 11, 12, 13, 14]]\n",
      "----\n",
      "****\n",
      "[[0, 1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21]]\n",
      "----\n",
      "[[0, 1, 2, 3, 4, 5], [6, 7, 8, 9, 10, 11, 12], [13, 14, 15, 16, 17, 18, 19, 20]]\n",
      "----\n",
      "[[0, 1, 2, 3, 4, 5, 6], [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]]\n",
      "----\n",
      "****\n",
      "[[0, 1, 2, 3, 4, 5], [6, 7, 8, 9, 10, 11], [12, 13, 14, 15, 16, 17, 18], [19, 20, 21, 22, 23, 24, 25, 26, 27]]\n",
      "----\n",
      "[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14], [15, 16, 17, 18, 19, 20, 21, 22, 23]]\n",
      "----\n",
      "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]]\n",
      "----\n",
      "****\n"
     ]
    }
   ],
   "source": [
    "for partition in Partitions:\n",
    "    for p in partition:\n",
    "        print(p)\n",
    "        print '----'\n",
    "    print ('****')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_feat=1321\n",
    "n_est=200\n",
    "klf=tree.DecisionTreeClassifier(max_depth=9)\n",
    "clfs=[tree.DecisionTreeClassifier(),tree.DecisionTreeClassifier(min_samples_split=16),tree.DecisionTreeClassifier(max_depth=6)]\n",
    "clfs+=[RandomForestClassifier(n_estimators=n_est, max_features=i,max_depth=9) for i in range(1,n_feat)]\n",
    "clfs+=[BaggingClassifier(base_estimator=klf,max_features=i,n_estimators=n_est) for i in range(1,n_feat)]\n",
    "clfs+=[GradientBoostingClassifier(n_estimators=n_est, learning_rate=1.0,max_depth=9, random_state=0)]\n",
    "clfs+=[AdaBoostClassifier(base_estimator=klf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_feat=1321\n",
    "n_est=200\n",
    "#n_feat_selection=[i*10 for i in range (1,n_feat/10+1)]\n",
    "#n_feat_selection=[5]+[i*10 for i in range(1,10)]+[100+i*20 for i in range(200/20)]+[300+i*30 for i in range(300/30)]+[600+100*i for i in range(500/100)]+[1321]\n",
    "#n_feat_selection=[5]+[i*20 for i in range(1,5)]+[100+i*40 for i in range(200/40)]+[300+i*60 for i in range(300/60)]+[600+250*i for i in range(500/250)]+[1321]\n",
    "n_feat_selection=[5]+[i*40 for i in range(1,2)]+[100+i*50 for i in range(200/50)]+[300+i*100 for i in range(300/100)]+[600+250*i for i in range(500/250)]+[1321]\n",
    "klf=tree.DecisionTreeClassifier(max_depth=9)\n",
    "clfs=[tree.DecisionTreeClassifier(),tree.DecisionTreeClassifier(min_samples_split=16),tree.DecisionTreeClassifier(max_depth=6)]\n",
    "clfs+=[RandomForestClassifier(n_estimators=n_est, max_features=i,max_depth=9,n_jobs=-1) for i in n_feat_selection]\n",
    "clfs+=[BaggingClassifier(base_estimator=klf,max_features=i,n_estimators=n_est,n_jobs=-1) for i in n_feat_selection]\n",
    "clfs+=[GradientBoostingClassifier(n_estimators=n_est, learning_rate=1.0,max_depth=9, random_state=0)]\n",
    "clfs+=[AdaBoostClassifier(base_estimator=klf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names=['tree','tree_min_slit_16','tree_max_depth_6']\n",
    "names+=['RandomForest_'+str(i)+'_f' for i in  n_feat_selection]\n",
    "names+=['Bagging_'+str(i)+'_f' for i in  n_feat_selection]\n",
    "names+=['GradientBoosting']\n",
    "names+=['AdaBoost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sizes=[120,70,50,35,30,25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 29)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clfs), len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_clf(clf,X,Y_q,features,test_size):\n",
    "    I=np.random.permutation(len(X))\n",
    "    M=[]\n",
    "    S=[]\n",
    "    Acc=[]\n",
    "    P=[]\n",
    "    R=[]\n",
    "    Conf=[]\n",
    "    for i in range(len(X)/test_size-1):\n",
    "        I_te=list(range(test_size*i,test_size*(i+1)))\n",
    "        I_tr=list(range(0,test_size*i))+list(range(test_size*(i+1),len(I)))\n",
    "        train=I[I_tr]\n",
    "        test=I[I_te]\n",
    "\n",
    "        XX = np.array([d[features] for d in X[train]])\n",
    "        y=Y_q[train] \n",
    "        clf = clf.fit(XX, y)\n",
    "        true=np.array([int(Y_q[t]) for t in test])\n",
    "        pred=np.array([int(clf.predict([X[t][features]])[0]) for t in test])\n",
    "        conf=confusion_matrix(true,pred) \n",
    "        recall=[0 if not conf[i,i] else float(conf[i,i])/sum(conf[i,:]) for i in range(len(conf[:,0]))]\n",
    "        precision=[0 if not conf[i,i] else float(conf[i,i])/sum(conf[:,i]) for i in range(len(conf[:,0]))]\n",
    "        \n",
    "        Conf.append(conf)\n",
    "        M.append(np.average(np.abs(true-pred)))\n",
    "        S.append(np.std(true-pred))\n",
    "        Acc.append(accuracy_score(true,pred))\n",
    "        R.append(recall)\n",
    "        P.append(precision)\n",
    "    return[M,S,Acc,R,P,Conf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeout(res,partition,aggr,features,names,filename,i):\n",
    "    f=open(filename,'a')\n",
    "    f.write(str(i)+';'+names[i]+';'+str(aggr)+';'+str(partition)+';'+str(features)+';'+str(res[0])+';'+str(res[1])+';'+str(res[2])+';'+str(res[3])+';'+str(res[4])+';\\n')\n",
    "    f.close()\n",
    "def writeout_c(conf,partition,aggr,features,names,filename,i):\n",
    "    f=open(filename,'a')\n",
    "    f.write(str(i)+';'+names[i]+';'+str(aggr)+';'+str(partition)+';'+str(features)+';\\n')\n",
    "    f.write(str(conf)+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename='report_acc_2'\n",
    "filename_c='report_conf_2'\n",
    "f=open(filename,'a')\n",
    "#f.write('n_classf;name_classf;h_aggregation;risk_bands;features;avg_distance_from_true;std_distance_from_true;accuracy;recalls;precisions\\n')\n",
    "f.close()\n",
    "f=open(filename_c,'a')\n",
    "#f.write('n_classf;name_classf;h_aggregation;risk_bands;features;confusion\\n')\n",
    "f.close()\n",
    "for aggr in range(2,7):\n",
    "    test_size=test_sizes[aggr-1]\n",
    "    if aggr==1:\n",
    "        Q=getfeat.get_composed_feat_1h()\n",
    "    else:\n",
    "        Q=getfeat.get_composed_feat_h(aggr)\n",
    "    X=Q[0].T\n",
    "    Y=Q[1]\n",
    "    if aggr==2:\n",
    "        for partition in Partitions[aggr-1][1:]:\n",
    "            Y_q=part(Y,partition)\n",
    "            features=list(range(n_feat))\n",
    "            for i in range(len(clfs)):\n",
    "                res=evaluate_clf(clfs[i],X,Y_q,features,test_size)\n",
    "                writeout(res,partition,aggr,features,names,filename,i)\n",
    "                writeout_c(res[-1],partition,aggr,features,names,filename_c,i)\n",
    "    else:\n",
    "        for partition in Partitions[aggr-1]:\n",
    "            Y_q=part(Y,partition)\n",
    "            features=list(range(n_feat))\n",
    "            for i in range(len(clfs)):\n",
    "                res=evaluate_clf(clfs[i],X,Y_q,features,test_size)\n",
    "                writeout(res,partition,aggr,features,names,filename,i)\n",
    "                writeout_c(res[-1],partition,aggr,features,names,filename_c,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10,\n",
       " 20,\n",
       " 30,\n",
       " 40,\n",
       " 50,\n",
       " 60,\n",
       " 70,\n",
       " 80,\n",
       " 90,\n",
       " 100,\n",
       " 120,\n",
       " 140,\n",
       " 160,\n",
       " 180,\n",
       " 200,\n",
       " 220,\n",
       " 240,\n",
       " 260,\n",
       " 280,\n",
       " 300,\n",
       " 330,\n",
       " 360,\n",
       " 390,\n",
       " 420,\n",
       " 450,\n",
       " 480,\n",
       " 510,\n",
       " 540,\n",
       " 570,\n",
       " 600,\n",
       " 700,\n",
       " 800,\n",
       " 900,\n",
       " 1000,\n",
       " 1321]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_feat_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
